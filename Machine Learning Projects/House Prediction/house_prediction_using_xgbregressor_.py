# -*- coding: utf-8 -*-
"""House Prediction using XGBRegressor .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19tMgIzZA7bIVUedLYq2YAbHtqTSOpGV8

# Import the Libraries
"""

## import some basic libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn.datasets
from sklearn.model_selection import train_test_split
from xgboost import XGBRegressor
from sklearn import metrics

"""# Importing the california Housing Dataset"""

from sklearn.datasets import fetch_california_housing
housing = fetch_california_housing()

print(housing)

# Loading the dataset to a Pandas DataFame
housing_df = pd.DataFrame(housing.data, columns=housing.feature_names)
housing_df.head()

# Add the target (price) column to the DataFame
housing_df['Price'] = housing.target
housing_df.head()

# Display the first few rows
print("First 5 rows of the dataset:")
print(housing_df.head())

# Check for missing values
missing_values = housing_df.isnull().sum()
print("\nMissing values in each column:")
print(missing_values)

# Statistical description of the dataset
print("\nStatistical Description of the Dataset:")
housing_df.describe()

# Correlation Heatmap
correlation = housing_df.corr()

# Create the heatmap with enhancements
plt.figure(figsize=(10, 8))
sns.heatmap(
    correlation,
    annot=True,
    fmt=".2f",
    cmap="coolwarm",
    cbar_kws={"shrink": 0.8},
    linewidths=0.5,
    square=True,
    annot_kws={"size": 8, "weight": "bold"},
)
plt.title("Enhanced Correlation Heatmap", fontsize=14, fontweight="bold", pad=15)
plt.xticks(fontsize=10, rotation=45, ha="right", weight="bold")
plt.yticks(fontsize=10, weight="bold")
plt.tight_layout()

# Splitting features and target
X = housing_df.drop(['Price'], axis=1)
y = housing_df['Price']

# Splitting the dataset into Training and Test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)
print("\nDataset split completed:")
print(f"Total samples: {X.shape[0]}, Training samples: {X_train.shape[0]}, Test samples: {X_test.shape[0]}")

# Initialize the model
xgb_model = XGBRegressor(random_state=1)

# Fit the model on the training data
xgb_model.fit(X_train, y_train)

# Evaluate on Training Data
training_data_prediction = xgb_model.predict(X_train)
r2_train = metrics.r2_score(y_train, training_data_prediction)
mae_train = metrics.mean_absolute_error(y_train, training_data_prediction)
print(f"\nTraining Data Evaluation:\nR-squared Error: {r2_train:.4f}\nMean Absolute Error: {mae_train:.4f}")

# Evaluate on Test Data
test_data_prediction = xgb_model.predict(X_test)
r2_test = metrics.r2_score(y_test, test_data_prediction)
mae_test = metrics.mean_absolute_error(y_test, test_data_prediction)
print(f"\nTest Data Evaluation:\nR-squared Error: {r2_test:.4f}\nMean Absolute Error: {mae_test:.4f}")

# Scatter Plot for Test Data
plt.figure(figsize=(8, 6))
plt.scatter(y_train, training_data_prediction, alpha=0.5, color='blue')
plt.xlabel("Actual Prices")
plt.ylabel("Predicted Prices")
plt.title("Train Data: Actual Prices vs Predicted Prices")

# Add Ideal Prediction Line
max_val = max(max(y_train), max(training_data_prediction))
min_val = min(min(y_train), min(training_data_prediction))
plt.plot([min_val, max_val], [min_val, max_val], color='red', label='Ideal Prediction')
plt.legend()
plt.show()

# Scatter Plot for Test Data
plt.figure(figsize=(8, 6))
plt.scatter(y_test, test_data_prediction, alpha=0.5, color='green')
plt.xlabel("Actual Prices")
plt.ylabel("Predicted Prices")
plt.title("Test Data: Actual Prices vs Predicted Prices")

# Add Ideal Prediction Line
max_val = max(max(y_test), max(test_data_prediction))
min_val = min(min(y_test), min(test_data_prediction))
plt.plot([min_val, max_val], [min_val, max_val], color='red', label='Ideal Prediction')
plt.legend()
plt.show()

"""## Considering Hyperparameter Tuning"""

from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.05, 0.1],
    'subsample': [0.8, 1],
    'colsample_bytree': [0.8, 1],
    'gamma': [0, 1, 5]
}

grid_search = GridSearchCV(estimator=XGBRegressor(random_state=1),
                           param_grid=param_grid,
                           scoring='r2',
                           cv=5,
                           verbose=1,
                           n_jobs=-1)

grid_search.fit(X_train, y_train)

print("Best parameters:", grid_search.best_params_)
print("Best cross-validation R2:", grid_search.best_score_)

# Evaluate on Training Data
training_data_prediction_gs = grid_search.predict(X_train)
r2_train = metrics.r2_score(y_train, training_data_prediction_gs)
mae_train = metrics.mean_absolute_error(y_train, training_data_prediction_gs)
print(f"\nTraining Data Evaluation:\nR-squared Error: {r2_train:.4f}\nMean Absolute Error: {mae_train:.4f}")

# Evaluate on Test Data
test_data_prediction_gs = xgb_model.predict(X_test)
r2_test = metrics.r2_score(y_test, test_data_prediction_gs)
mae_test = metrics.mean_absolute_error(y_test, test_data_prediction_gs)
print(f"\nTest Data Evaluation:\nR-squared Error: {r2_test:.4f}\nMean Absolute Error: {mae_test:.4f}")

model = XGBRegressor(
    colsample_bytree=0.8,
    gamma=0,
    learning_rate=0.1,
    max_depth=7,
    n_estimators=300,
    subsample=0.8,
    reg_alpha=1,  # L1 regularization
    reg_lambda=1  # L2 regularization
)


from sklearn.model_selection import cross_val_score

cv_scores = cross_val_score(model, X, y, cv=5, scoring='r2')
print("Cross-Validation R² Scores:", cv_scores)
print("Mean Cross-Validation R²:", np.mean(cv_scores))

"""# Transforming the Dataset. Also, consider polynomial features or scaling"""

from sklearn.preprocessing import PolynomialFeatures

poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)
X_poly = poly.fit_transform(X)

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split transformed data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=1)


model.fit(X_train, y_train)

# Predictions for Training Data
training_preds = model.predict(X_train)
r2_train = metrics.r2_score(y_train, training_preds)
mae_train = metrics.mean_absolute_error(y_train, training_preds)
print(f"\nTraining Data Evaluation:\nR-squared Error: {r2_train:.4f}\nMean Absolute Error: {mae_train:.4f}")

# Predictions for Test Data
test_preds = model.predict(X_test)
r2_test = metrics.r2_score(y_test, test_preds)
mae_test = metrics.mean_absolute_error(y_test, test_preds)
print(f"\nTest Data Evaluation:\nR-squared Error: {r2_test:.4f}\nMean Absolute Error: {mae_test:.4f}")

# Scatter Plot for Test Data
plt.figure(figsize=(8, 6))
plt.scatter(y_train, training_preds, alpha=0.5, color='blue')
plt.xlabel("Actual Prices")
plt.ylabel("Predicted Prices")
plt.title("Train Data: Actual Prices vs Predicted Prices")

# Add Ideal Prediction Line
max_val = max(max(y_train), max(training_preds))
min_val = min(min(y_train), min(training_preds))
plt.plot([min_val, max_val], [min_val, max_val], color='red', label='Ideal Prediction')
plt.legend()
plt.show()

# Scatter Plot for Test Data
plt.figure(figsize=(8, 6))
plt.scatter(y_test, test_preds, alpha=0.5, color='green')
plt.xlabel("Actual Prices")
plt.ylabel("Predicted Prices")
plt.title("Test Data: Actual Prices vs Predicted Prices")

# Add Ideal Prediction Line
max_val = max(max(y_test), max(test_preds))
min_val = min(min(y_test), min(test_preds))
plt.plot([min_val, max_val], [min_val, max_val], color='red', label='Ideal Prediction')
plt.legend()
plt.show()

"""## **Try Different Algorithms**"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.linear_model import Ridge, Lasso
from sklearn.svm import SVR

# Initialize different models
models = {
    "Random Forest": RandomForestRegressor(random_state=1),
    "Gradient Boosting": GradientBoostingRegressor(random_state=1),
    "Ridge Regression": Ridge(),
    "Lasso Regression": Lasso(),
    "SVR": SVR()
}

# Evaluate models
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    r2 = metrics.r2_score(y_test, y_pred)
    mae = metrics.mean_absolute_error(y_test, y_pred)
    print(f"{name} - R2: {r2:.4f}, MAE: {mae:.4f}")

from sklearn.ensemble import GradientBoostingRegressor

gbr = GradientBoostingRegressor(random_state=1)
gbr.fit(X_train, y_train)

# Evaluate the model
y_pred_train = gbr.predict(X_train)
y_pred_test = gbr.predict(X_test)

r2_train = metrics.r2_score(y_train, y_pred_train)
mae_train = metrics.mean_absolute_error(y_train, y_pred_train)

r2_test = metrics.r2_score(y_test, y_pred_test)
mae_test = metrics.mean_absolute_error(y_test, y_pred_test)

print(f"GradientBoostingRegressor - Training R2: {r2_train:.4f}, MAE: {mae_train:.4f}")
print(f"GradientBoostingRegressor - Test R2: {r2_test:.4f}, MAE: {mae_test:.4f}")