# -*- coding: utf-8 -*-
"""Breast Cancer Classification using LogisticRegression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p14A6W6tGEnkOM8NCPosw-A96Vnewkdk

#**About Dataset**

Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image.

**n** the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: "Robust Linear Programming Discrimination of Two Linearly Inseparable Sets", Optimization Methods and Software 1, 1992, 23-34].

This database is also available through the **UW CS ftp server:**

**ftp ftp.cs.wisc.edu**

**cd math-prog/cpo-dataset/machine-learn/WDBC/**

Also can be found on UCI Machine Learning Repository:

 https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29

**Attribute Information:**

1) ID number

2) Diagnosis (M = malignant, B = benign)

3-32)

Ten real-valued features are computed for each cell nucleus:

a) radius (mean of distances from center to points on the perimeter)

b) texture (standard deviation of gray-scale values)

c) perimeter

d) area

e) smoothness (local variation in radius lengths)

f) compactness (perimeter^2 / area - 1.0)

g) concavity (severity of concave portions of the contour)

h) concave points (number of concave portions of the contour)

i) symmetry

j) fractal dimension ("coastline approximation" - 1)

The mean, standard error and "worst" or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features. For instance,

**field 3 is Mean Radius,**

**field 13 is Radius SE,**

**field 23 is Worst Radius.**

All feature values are recoded with four significant digits.

**Missing attribute values:**  **none**


**Class distribution:**

**357 benign,**

**212 malignant**

#**Import the Libraries**
"""

## import some basic libraries
import numpy as np
import pandas as pd
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

"""#**Data Collection and Preprocessing**"""

# Loading the data from sklearn
breast_cancer_data = load_breast_cancer()
print(breast_cancer_data)

# Loading the dataset to a DataFrame
df = pd.DataFrame(breast_cancer_data.data, columns = breast_cancer_data.feature_names)

# Display the first few rows
print("First 5 rows of the dataset:")
df.head()

# Adding the 'target' column to the data frame
df['label'] = breast_cancer_data.target

# Display the last few rows
print("last 5 rows of the dataset:")
df.tail()

# Numbers of rows and columns in the dataset
df.shape   # Outputs the number of rows and columns in the dataset.

# Getting some informations about the datasets
df.info()

# Check for missing values
missing_values = df.isnull().sum()
print("\nMissing values in each column:")
print(missing_values)

# Statistical description of the dataset
print("\nStatistical Description of the Dataset:")
df.describe()

# Checking the distribution of Target Variable
print("\nStatistical Distribution of the Dataset:")
df['label'].value_counts()

"""**1 ---> Benign**

**0 ---> Malignant**
"""

# Checking the Mean distribution of Target Variable
print("\nMean Distribution of the Dataset:")
df.groupby('label').mean()

"""**Splitting the dataset into Features & Target**"""

# Splitting the dataset into Features & Target
X = df.drop(columns="label", axis=1)
y = df["label"]

print("Features (X):")
print(X.head())
print("\nTarget (y):")
print(y.head())

"""# **Splitting the dataset into Training and Test sets**"""

# Splitting the dataset into Training and Test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=3)
print("\nDataset split completed:")
print(f"Total samples: {X.shape[0]}, Training samples: {X_train.shape[0]}, Test samples: {X_test.shape[0]}")

# checking the number of Test and Train dataset
print(X.shape, X_train.shape, X_test.shape)

"""# **Model Training**"""

# Initialize the model
logReg_model = LogisticRegression()

# Training the LogisticRegression model with train data
logReg_model.fit(X_train, y_train)

"""#**Model Evaluation**"""

# Calculate accuracy on the training data
X_train_pred = logReg_model.predict(X_train)
train_data_accuracy = accuracy_score(X_train_pred, y_train)
print('Accuracy on training data : ', train_data_accuracy)

# Generate and display the confusion matrix on the training data
# The confusion matrix shows the counts of True Positives, True Negatives, False Positives, and False Negatives
conf_matrix = confusion_matrix(y_train, X_train_pred)
print("\nConfusion Matrix:")
print(conf_matrix)

# Generate and display the classification report
# The classification report includes precision, recall, F1-score, and support for each class
class_report = classification_report(y_train, X_train_pred, target_names=["Malignant Breast Cancer  (0)", "Benign Breast Cancer  (1)"])
print("\nClassification Report:")
print(class_report)

# accuracy on the test data
X_test_pred = logReg_model.predict(X_test)
test_data_accuracy = accuracy_score(X_test_pred, y_test)
print('Accuracy on test data : ', test_data_accuracy)

# Generate and display the confusion matrix on the test data
# The confusion matrix shows the counts of True Positives, True Negatives, False Positives, and False Negatives
conf_matrix = confusion_matrix(y_test, X_test_pred)
print("\nConfusion Matrix:")
print(conf_matrix)

# Generate and display the classification report
# The classification report includes precision, recall, F1-score, and support for each class
class_report = classification_report(y_test, X_test_pred, target_names=["Malignant Breast Cancer (0)", "Benign Breast Cancer  (1)"])
print("\nClassification Report:")
print(class_report)

"""# **Making a Predictive System**"""

# Sample input data (new instance to classify)
input_data = [12.45,15.7,82.57,477.1,0.1278,0.17,0.1578,0.08089,0.2087,0.07613,0.3345,0.8902,2.217,27.19,0.00751,0.03345,0.03672,0.01137,0.02165,0.005082,15.47,23.75,103.4,741.6,0.1791,0.5249,0.5355,0.1741,0.3985,0.1244]

# Converting input data to a NumPy array
input_data_as_numpy_array = np.asarray(input_data)

# Reshaping the input array for prediction (to match model's expected input shape)
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

# Making a prediction
prediction = logReg_model.predict(input_data_reshaped)
print(prediction)

# Outputting the result
if prediction[0] == 0:
    print("The Breast Cancer is Malignant (i.e. Malignant)")
else:
    print("The Breast Cancer is Benign (i.e. Benign)")

# Sample input data (new instance to classify)
input_data = [13.08,15.71,85.63,520,0.1075,0.127,0.04568,0.0311,0.1967,0.06811,0.1852,0.7477,1.383,14.67,0.004097,0.01898,0.01698,0.00649,0.01678,0.002425,14.5,20.49,96.09,630.5,0.1312,0.2776,0.189,0.07283,0.3184,0.08183]

# Converting input data to a NumPy array
input_data_as_numpy_array = np.asarray(input_data)

# Reshaping the input array for prediction (to match model's expected input shape)
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

# Making a prediction
prediction = logReg_model.predict(input_data_reshaped)
print(prediction)

# Outputting the result
if prediction[0] == 0:
    print("The Breast Cancer is Malignant (i.e. Malignant)")
else:
    print("The Breast Cancer is Benign (i.e. Benign)")