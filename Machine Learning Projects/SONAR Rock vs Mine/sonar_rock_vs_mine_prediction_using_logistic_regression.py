# -*- coding: utf-8 -*-
"""SONAR_Rock_vs_Mine_Prediction_using_Logistic_Regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pzMTfiLOWz15FOGyDTQq0xs0hQqF7RBy

# **Import the Libraries**
"""

## import some basic libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report

"""# **Data Collection and Data Preprocessing**"""

# Loading the dataset into a pandas DataFrame
sonar = pd.read_csv('sonar.csv', header=None)  # Dataset is read without headers.
sonar.head()  # Displays the first 5 rows of the dataset.

# Checking the shape of the dataset
sonar.shape  # Outputs the number of rows and columns in the dataset.

# Statistical description of the dataset
sonar.describe()  # Provides a summary of statistics for numeric columns.

# Analyzing the target column (last column [60])
# Counts the occurrences of 'M' (Mine) and 'R' (Rock).
sonar[60].value_counts()

"""# 'M' indicates Mine and 'R' indicates Rock.

**M---> Mine**

**R---> Rock**
"""

# Grouping the dataset by target column and calculating the mean of features for each group.
sonar.groupby(60).mean()

# Extracting column names
sonar.columns  # Outputs column indices.
column_names = sonar.columns
print(column_names)

"""# Splitting features (X) and target (y) using different methods.

X = Independent (Features variables)

y = Dependent (Target variables)
"""

# Method 1: Use all columns except the last for features and the last column as the target.
X1 = sonar.iloc[:, 0:-1]
y1 = sonar.iloc[:, -1]

# Method 2: Use column indices explicitly.
X2 = sonar.iloc[:, 0:60]
y2 = sonar.iloc[:, 60]

# Method 3: Use drop() to exclude the last column for features.
X3 = sonar.drop(columns=sonar.columns[-1], axis=1)
y3 = sonar[sonar.columns[-1]]

# Method 4: Another variation using explicit column index for target.
X4 = sonar.drop(columns=60, axis=1)
y4 = sonar[60]

# Comparing the equality of different feature and target extraction methods.
X1_equals_X2 = X1.equals(X2)
X2_equals_X3 = X2.equals(X3)
X3_equals_X4 = X3.equals(X4)
y1_equals_y2 = y1.equals(y2)
y2_equals_y3 = y2.equals(y3)
y3_equals_y4 = y3.equals(y4)

print(X1_equals_X2, X2_equals_X3, X3_equals_X4, y1_equals_y2, y2_equals_y3, y3_equals_y4)

## X = Independent (Features variables)
## y = Dependent (Target variables)

X = sonar.iloc[:, 0:-1]
y = sonar.iloc[:, -1]

## OR
X = sonar.iloc[:, 0:60]
y = sonar.iloc[:, 60]

## OR
X = sonar.drop(columns=60, axis=1)
y = sonar[60]

## OR
X = sonar.drop(columns=sonar.columns[-1], axis=1)
y = sonar[sonar.columns[-1]]

print(X)
print(y)

"""# **Split the Dataset into Training and Test Sets**"""

# Splitting the dataset into Training set and Test Set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=1)

"""X: The feature set.
y: The target variable.

**test_size=0.1:** 10% of the data will be allocated to the test set, and 90% to the training set.

**stratify=y:** Ensures that the class distribution in y is preserved in both the training and test sets.

**random_state=1:** Sets the seed for random number generation, ensuring reproducibility of the split.

In summary, **stratify=y** helps to maintain the same class distribution in the training and test sets as in the original dataset, which is crucial for training and evaluating models on balanced data.This is particularly useful when you have an imbalanced dataset







"""

# checking the number of Test and Train dataset
print(X.shape, X_train.shape, X_test.shape)

"""# **Model Training --> Logistic Regression**"""

# Initializing the Logistic Regression mod
model = LogisticRegression()

# Training the Logistic Regression model with train data
model.fit(X_train, y_train)

"""# **Model Evaluation**"""

# accuracy on the training data
X_train_pred = model.predict(X_train)
train_data_accuracy = accuracy_score(X_train_pred, y_train)
print('Accuracy on training data : ', train_data_accuracy)

# accuracy on the test data
X_test_pred = model.predict(X_test)
test_data_accuracy = accuracy_score(X_test_pred, y_test)
print('Accuracy on test data : ', test_data_accuracy)

"""# **Making a Predictive System**"""

# Sample input data (new instance to classify)
input_data = [0.0187,0.0346,0.0168,0.0177,0.0393,0.1630,0.2028,0.1694,0.2328,0.2684,0.3108,0.2933,0.2275,0.0994,0.1801,0.2200,0.2732,0.2862,0.2034,0.1740,0.4130,0.6879,0.8120,0.8453,0.8919,0.9300,0.9987,1.0000,0.8104,0.6199,0.6041,0.5547,0.4160,0.1472,0.0849,0.0608,0.0969,0.1411,0.1676,0.1200,0.1201,0.1036,0.1977,0.1339,0.0902,0.1085,0.1521,0.1363,0.0858,0.0290,0.0203,0.0116,0.0098,0.0199,0.0033,0.0101,0.0065,0.0115,0.0193,0.0157]

# Converting input data to a NumPy array
input_data_as_numpy_array = np.asarray(input_data)

# Reshaping the input array for prediction (to match model's expected input shape)
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

# Making a prediction
prediction = model.predict(input_data_reshaped)
print(prediction)

# Outputting the result
if (prediction[0]=='R'):
  print('The object is a Rock')
else:
  print('The object is a Mine')

# Sample input data (new instance to classify)
input_data = [0.0223,0.0375,0.0484,0.0475,0.0647,0.0591,0.0753,0.0098,0.0684,0.1487,0.1156,0.1654,0.3833,0.3598,0.1713,0.1136,0.0349,0.3796,0.7401,0.9925,0.9802,0.8890,0.6712,0.4286,0.3374,0.7366,0.9611,0.7353,0.4856,0.1594,0.3007,0.4096,0.3170,0.3305,0.3408,0.2186,0.2463,0.2726,0.1680,0.2792,0.2558,0.1740,0.2121,0.1099,0.0985,0.1271,0.1459,0.1164,0.0777,0.0439,0.0061,0.0145,0.0128,0.0145,0.0058,0.0049,0.0065,0.0093,0.0059,0.0022]

# Converting input data to a NumPy array
input_data_as_numpy_array = np.asarray(input_data)

# Reshaping the input array for prediction (to match model's expected input shape)
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

# Making a prediction
prediction = model.predict(input_data_reshaped)
print(prediction)

# Outputting the result
if (prediction[0]=='R'):
  print('The object is a Rock')
else:
  print('The object is a Mine')