# -*- coding: utf-8 -*-
"""Car Price Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eZlyCAuhVAYXpQ_HOvAgYezf115ZlxjK

# **Vehicle dataset**

**Used Cars data form websites**

About Dataset
This dataset contains information about used cars.
This data can be used for a lot of purposes such as price prediction to exemplify the use of linear regression in Machine Learning.

**The columns in the given dataset are as follows:**

1. name
2. year
3. selling_price
4. km_driven
5. fuel
6. seller_type
7. transmission
8. Owner

# **Import necessary tools**
"""

pip install --upgrade xgboost scikit-learn

pip install gradio

"""#**Import the Libraries**"""

## import some basic libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, Lasso
from sklearn.ensemble import GradientBoostingRegressor
from sklearn import metrics

"""#**Data Collecction and Preprocessing**"""

# Loading the dataset into a pandas DataFrame
car_data = pd.read_csv('car data.csv')  # Use this to identify issues

# Display the first few rows
print("First 5 rows of the dataset:")
car_data.head()

# Checking the shape of the dataset
car_data.shape    # Outputs the number of rows and columns in the dataset.

# Statistical description of the dataset
print("\nStatistical Description of the Dataset:")
car_data.describe()

# Check for missing values
missing_values = car_data.isnull().sum()
print("\nMissing values in each column:")
print(missing_values)

# Geerating some Information about the dataset
car_data.info()

# Checking the distribution of categorical data
print("\nDistribution of Categorical Data:")
print(car_data['Fuel_Type'].value_counts())
print(car_data['Seller_Type'].value_counts())
print(car_data['Transmission'].value_counts())

""" **Encoding the Categorical data**"""

# Encoding "Fuel_Type" Column
car_data.replace({'Fuel_Type':{'Petrol':0,'Diesel':1,'CNG':2}},inplace=True)

# Encoding "Seller_Type" Column
car_data.replace({'Seller_Type':{'Dealer':0,'Individual':1}},inplace=True)

# Encoding the "Transmission" Column
car_data.replace({'Transmission':{'Manual':0,'Automatic':1}},inplace=True)

# Display the first few rows
print("First 5 rows of the dataset:")
car_data.head()

# Data Understanding & Validation
sns.pairplot(car_data)
plt.show()

# Splitting features and target
X = car_data.drop(columns=['Car_Name','Selling_Price'], axis=1)
y = car_data['Selling_Price']

print("Features (X):")
print(X.head())
print("\nTarget (y):")
print(y.head())

"""# **Splitting the dataset into Training and Test sets**"""

# Splitting the dataset into Training and Test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)
print("\nDataset split completed:")
print(f"Total samples: {X.shape[0]}, Training samples: {X_train.shape[0]}, Test samples: {X_test.shape[0]}")

# checking the number of Test and Train dataset
print(X.shape, X_train.shape, X_test.shape)

"""# **Model Training**

1. **Linear Regression**
"""

# Initialize the model
ling_model = LinearRegression()

# Training the Linear Regression model with train data
ling_model.fit(X_train, y_train)

"""#**Model Evaluation**"""

# Evaluate on Training Data
training_data_prediction = ling_model.predict(X_train)
r2_train = metrics.r2_score(y_train, training_data_prediction)
mae_train = metrics.mean_absolute_error(y_train, training_data_prediction)
print(f"\nTraining Data Evaluation:\nR-squared Error: {r2_train:.4f}\nMean Absolute Error: {mae_train:.4f}")

# Evaluate on Test Data
test_data_prediction = ling_model.predict(X_test)
r2_test = metrics.r2_score(y_test, test_data_prediction)
mae_test = metrics.mean_absolute_error(y_test, test_data_prediction)
print(f"\nTest Data Evaluation:\nR-squared Error: {r2_test:.4f}\nMean Absolute Error: {mae_test:.4f}")

# Scatter Plot for Train Data
plt.scatter(y_train, training_data_prediction, alpha=0.5, color='blue')
plt.xlabel("Actual Prices")
plt.ylabel("Predicted Prices")
plt.title("Train Data: Actual Prices vs Predicted Prices")

# Add Ideal Prediction Line
max_val = max(max(y_train), max(training_data_prediction))
min_val = min(min(y_train), min(training_data_prediction))
plt.plot([min_val, max_val], [min_val, max_val], color='red', label='Ideal Prediction')
plt.legend()
plt.show()

# Scatter Plot for Test Data
plt.figure(figsize=(8, 6))
plt.scatter(y_test, test_data_prediction, alpha=0.5, color='green')
plt.xlabel("Actual Prices")
plt.ylabel("Predicted Prices")
plt.title("Test Data: Actual Prices vs Predicted Prices")

# Add Ideal Prediction Line
max_val = max(max(y_test), max(test_data_prediction))
min_val = min(min(y_test), min(test_data_prediction))
plt.plot([min_val, max_val], [min_val, max_val], color='red', label='Ideal Prediction')
plt.legend()
plt.show()

"""2. **Lasso Regression**"""

# Initialize the model
lass_model = Lasso()

# Training the Linear Regression model with train data
lass_model.fit(X_train, y_train)

"""#**Model Evaluation**"""

# Evaluate on Training Data
training_data_prediction = lass_model.predict(X_train)
r2_train = metrics.r2_score(y_train, training_data_prediction)
mae_train = metrics.mean_absolute_error(y_train, training_data_prediction)
print(f"\nTraining Data Evaluation:\nR-squared Error: {r2_train:.4f}\nMean Absolute Error: {mae_train:.4f}")

# Evaluate on Test Data
test_data_prediction = lass_model.predict(X_test)
r2_test = metrics.r2_score(y_test, test_data_prediction)
mae_test = metrics.mean_absolute_error(y_test, test_data_prediction)
print(f"\nTest Data Evaluation:\nR-squared Error: {r2_test:.4f}\nMean Absolute Error: {mae_test:.4f}")

# Scatter Plot for Train Data
plt.scatter(y_train, training_data_prediction, alpha=0.5, color='blue')
plt.xlabel("Actual Prices")
plt.ylabel("Predicted Prices")
plt.title("Train Data: Actual Prices vs Predicted Prices")

# Add Ideal Prediction Line
max_val = max(max(y_train), max(training_data_prediction))
min_val = min(min(y_train), min(training_data_prediction))
plt.plot([min_val, max_val], [min_val, max_val], color='red', label='Ideal Prediction')
plt.legend()
plt.show()

# Scatter Plot for Test Data
plt.scatter(y_test, test_data_prediction, alpha=0.5, color='green')
plt.xlabel("Actual Prices")
plt.ylabel("Predicted Prices")
plt.title("Test Data: Actual Prices vs Predicted Prices")

# Add Ideal Prediction Line
max_val = max(max(y_test), max(test_data_prediction))
min_val = min(min(y_test), min(test_data_prediction))
plt.plot([min_val, max_val], [min_val, max_val], color='red', label='Ideal Prediction')
plt.legend()
plt.show()

"""**Consider XGBRegressor**"""

# Initialize the model
GBR_model = GradientBoostingRegressor(random_state=1)

# Fit the model on the training data
GBR_model.fit(X_train, y_train)

# Evaluate on Training Data
training_data_prediction = GBR_model.predict(X_train)
r2_train = metrics.r2_score(y_train, training_data_prediction)
mae_train = metrics.mean_absolute_error(y_train, training_data_prediction)
print(f"\nTraining Data Evaluation:\nR-squared Error: {r2_train:.4f}\nMean Absolute Error: {mae_train:.4f}")

# Evaluate on Test Data
test_data_prediction = GBR_model.predict(X_test)
r2_test = metrics.r2_score(y_test, test_data_prediction)
mae_test = metrics.mean_absolute_error(y_test, test_data_prediction)
print(f"\nTest Data Evaluation:\nR-squared Error: {r2_test:.4f}\nMean Absolute Error: {mae_test:.4f}")

# Scatter Plot for Train Data
plt.scatter(y_train, training_data_prediction, alpha=0.5, color='blue')
plt.xlabel("Actual Prices")
plt.ylabel("Predicted Prices")
plt.title("Train Data: Actual Prices vs Predicted Prices")

# Add Ideal Prediction Line
max_val = max(max(y_train), max(training_data_prediction))
min_val = min(min(y_train), min(training_data_prediction))
plt.plot([min_val, max_val], [min_val, max_val], color='red', label='Ideal Prediction')
plt.legend()
plt.show()

# Scatter Plot for Test Data
plt.scatter(y_test, test_data_prediction, alpha=0.5, color='green')
plt.xlabel("Actual Prices")
plt.ylabel("Predicted Prices")
plt.title("Test Data: Actual Prices vs Predicted Prices")

# Add Ideal Prediction Line
max_val = max(max(y_test), max(test_data_prediction))
min_val = min(min(y_test), min(test_data_prediction))
plt.plot([min_val, max_val], [min_val, max_val], color='red', label='Ideal Prediction')
plt.legend()
plt.show()

"""**Model Tuning**"""

# Using hyperparameter tuning for each model to optimize performance
from sklearn.model_selection import GridSearchCV

param_grid = {
    'learning_rate': [0.01, 0.1, 0.2],
    'n_estimators': [50, 100, 200],
    'max_depth': [3, 5, 7]
}
gbr = GradientBoostingRegressor(random_state=1)
grid_search = GridSearchCV(estimator=gbr, param_grid=param_grid, cv=5, scoring='r2')
grid_search.fit(X_train, y_train)
print("Best parameters:", grid_search.best_params_)

# Evaluate on Training Data
training_data_prediction_gs = grid_search.predict(X_train)
r2_train = metrics.r2_score(y_train, training_data_prediction_gs)
mae_train = metrics.mean_absolute_error(y_train, training_data_prediction_gs)
print(f"\nTraining Data Evaluation:\nR-squared Error: {r2_train:.4f}\nMean Absolute Error: {mae_train:.4f}")

# Evaluate on Test Data
test_data_prediction_gs = grid_search.predict(X_test)
r2_test = metrics.r2_score(y_test, test_data_prediction_gs)
mae_test = metrics.mean_absolute_error(y_test, test_data_prediction_gs)
print(f"\nTest Data Evaluation:\nR-squared Error: {r2_test:.4f}\nMean Absolute Error: {mae_test:.4f}")

"""**Pipeline Integration**"""

# Build a Pipeline to streamline preprocessing and modeling
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler

pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('regressor', GradientBoostingRegressor(random_state=1))
])
pipeline.fit(X_train, y_train)

# Evaluate on Training Data
training_data_prediction_gs = pipeline.predict(X_train)
r2_train = metrics.r2_score(y_train, training_data_prediction_gs)
mae_train = metrics.mean_absolute_error(y_train, training_data_prediction_gs)
print(f"\nTraining Data Evaluation:\nR-squared Error: {r2_train:.4f}\nMean Absolute Error: {mae_train:.4f}")

# Evaluate on Test Data
test_data_prediction_gs = pipeline.predict(X_test)
r2_test = metrics.r2_score(y_test, test_data_prediction_gs)
mae_test = metrics.mean_absolute_error(y_test, test_data_prediction_gs)
print(f"\nTest Data Evaluation:\nR-squared Error: {r2_test:.4f}\nMean Absolute Error: {mae_test:.4f}")

"""**Model Comparison**"""

# Evaluating all models in a unified framework
models = {
    'Linear Regression': ling_model,
    'Lasso': lass_model,
    'Gradient Boosting': GBR_model
}

for name, model in models.items():
    y_pred = model.predict(X_test)
    r2 = metrics.r2_score(y_test, y_pred)
    mae = metrics.mean_absolute_error(y_test, y_pred)
    print(f"{name} - R^2: {r2:.4f}, MAE: {mae:.4f}")

"""**Residual analysis**"""

residuals = y_test - test_data_prediction
plt.figure(figsize=(8, 6))
sns.histplot(residuals, kde=True)
plt.title("Residual Distribution")
plt.show()