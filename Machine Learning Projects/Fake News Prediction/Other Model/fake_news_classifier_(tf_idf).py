# -*- coding: utf-8 -*-
"""Fake News Classifier (TF-IDF).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/196y_GEEfmx56fiapcZfnyx_153_W3zBs

# **Fake News Classifier**

Dataset: https://www.kaggle.com/c/fake-news/data#
"""

!pip install --upgrade scikit-learn

import pandas as pd

news = pd.read_csv("train.txt", on_bad_lines='skip', engine='python')

news.head()

# Get the Independent Features
X = news.drop("label", axis=1)

X.head()

#  Get the Dependent features
y = news["label"]

y.head()

news.shape

from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer

news = news.dropna()

news.shape

news.head(10)

mess = news.copy ()

mess.reset_index(inplace=True)

mess.head(10)

mess["text"][9]

# import Libraries
import nltk

# Ensure the punkt resource is downloaded
nltk.download('punkt') # Punkt resource is needed for sentence tokenization, punkt_tab is a specific internal representation
nltk.download('punkt_tab') # Download the resource explicitly

# Download the stopwords resource
nltk.download('stopwords')

import re
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
ps = PorterStemmer()
corpus = []
for i in range(0, len(mess)):
    review = re.sub('[^a-zA-Z]', ' ', mess['text'][i])
    review = review.lower()
    review = review.split()

    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]
    review = ' '.join(review)
    corpus.append(review)

corpus[5]

print(corpus[7])

# Tfidf Vectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
tfidf_vect = TfidfVectorizer(max_features=5000,ngram_range=(1,3))
X = tfidf_vect.fit_transform(corpus).toarray()

"""**max_features=5000:**

- This limits the vocabulary to the top 5000 most frequent words/phrases across your corpus.

- It helps reduce dimensionality and remove less informative words.

**ngram_range=(1, 3):**

- This tells the vectorizer to consider:

    - Unigrams (single words),

    - Bigrams (two-word phrases),

    - Trigrams (three-word phrases).

- Example: "machine learning is fun" will generate:

    - Unigrams: ["machine", "learning", "is", "fun"]

    - Bigrams: ["machine learning", "learning is", "is fun"]

    - Trigrams: ["machine learning is", "learning is fun"]
"""

X.shape

y = mess['label']

# Split the dataset into Train and Testtfidf_v.get_feature_names()[:20]
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=42)

tfidf_vect.get_feature_names_out()[:20]

# cv.get_feature_names()[:20]  # See all features name by ngram_range=(1,3) (old code)
tfidf_vect.get_feature_names_out()[:20]  # first 20 features (words or n-grams) selected by your CountVectorizer

tfidf_vect.get_params()  # Referring to TF-IDF model

tfidf_vect.get_params()

count_df = pd.DataFrame(X_train, columns=tfidf_vect.get_feature_names_out())

count_df.head()

import matplotlib.pyplot as plt

def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    See full source and example:
    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html

    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

"""**MultinomialNB Algorithm**

it works well for text data, and it suppported multiple categories of output
"""

from sklearn.naive_bayes import MultinomialNB
classifier=MultinomialNB()

from sklearn import metrics
import numpy as np
import itertools

classifier.fit(X_train, y_train)
pred = classifier.predict(X_test)
score = metrics.accuracy_score(y_test, pred)
print("accuracy:   %0.3f" % score)
conf_mtrx = metrics.confusion_matrix(y_test, pred)
plot_confusion_matrix(conf_mtrx, classes=['FAKE', 'REAL'])

classifier.fit(X_train, y_train)
pred = classifier.predict(X_test)
acc_score = metrics.accuracy_score(y_test, pred)
acc_score

y_train.shape

"""**Passive Aggressive Classifier Algorithm**

it works well with text data
"""

from sklearn.linear_model import PassiveAggressiveClassifier
linear_clf = PassiveAggressiveClassifier(max_iter=50)  # n_ite (old)

linear_clf.fit(X_train, y_train)
pred = linear_clf.predict(X_test)
score = metrics.accuracy_score(y_test, pred)
print("accuracy:   %0.3f" % score)
cm = metrics.confusion_matrix(y_test, pred)
plot_confusion_matrix(cm, classes=['FAKE Data', 'REAL Data'])

"""**Multinomial Classifier with Hyperparameter**"""

classifier = MultinomialNB(alpha=0.1)

#  looping over values of alpha from 0 to 0.9. For each alpha, training a new model and checking its accuracy.
#  keep the best performing classifier.
previous_score = 0
for alpha in np.arange(0,1,0.1):
    sub_classifier = MultinomialNB(alpha=alpha)
    sub_classifier.fit(X_train,y_train)
    y_pred = sub_classifier.predict(X_test)
    score = metrics.accuracy_score(y_test, y_pred)
    if score>previous_score:
        classifier=sub_classifier
    print("Alpha: {}, Score : {}".format(alpha,score))

# Get feature names from CountVectorizer
feature_names = tfidf_vect.get_feature_names_out()

classifier.coef_[0]

### Most real
sorted(zip(classifier.coef_[0], feature_names), reverse=True)[:20]

### Most fake
sorted(zip(classifier.coef_[0], feature_names))[:5000]

"""### Why **classifier.coef_** sometimes works with **MultinomialNB**
Normally, **MultinomialNB** from **sklearn.naive_bayes** does not document **coef_** as a public attribute.

However, **coef_** is a hidden alias for **feature_log_prob_** that:

- only exists if your data has 2 classes

- is created for consistency with other scikit-learn classifiers (like LogisticRegression)

- is sometimes removed in future versions, so it might break even if it works now

So when your guide code uses **classifier.coef_**, it works **only because**:

- You're doing binary classification

- You're using a version of scikit-learn that still exposes **coef_** as an alias

### **Official and Safer Alternative**
**Use this (official and stable):**

classifier.feature_log_prob_[0]

**Or to get the feature importance difference between classes:**

classifier.feature_log_prob_[1] - classifier.feature_log_prob_[0]

"""

# Use feature_log_prob_ instead of coef_
classifier.feature_log_prob_[0]

# feature importance difference between classes
classifier.feature_log_prob_[1] - classifier.feature_log_prob_[0]

# Use feature_log_prob_ to get real_class_features
real_class_features = classifier.feature_log_prob_[1]

# Use feature_log_prob_ to get fake_class_features
fake_class_features = classifier.feature_log_prob_[0]

# Get most indicative features for REAL news
most_real = sorted(zip(real_class_features, feature_names), reverse=True)[:20]
print("Most Real News Features:\n")
for score, word in most_real:
    print(f"{word}: {score:.4f}")

# Get most indicative features for FAKE news
most_fake = sorted(zip(fake_class_features, feature_names), reverse=True)[:20]
print("\nMost Fake News Features:\n")
for score, word in most_fake:
    print(f"{word}: {score:.4f}")

"""**How to Get the Most Informative Features**"""

# Get log probabilities for each class
log_probs = classifier.feature_log_prob_

# Top features for 'real' class (assuming real is class 1)
top_real = np.argsort(log_probs[1])[::-1][:20]
print("Top 20 features for REAL news:")
print([feature_names[i] for i in top_real])

# Top features for 'fake' class (assuming fake is class 0)
top_fake = np.argsort(log_probs[0])[::-1][:20]
print("\nTop 20 features for FAKE news:")
print([feature_names[i] for i in top_fake])

"""**View Feature Weights Sorted Together**"""

# Difference in log probabilities: higher = more real, lower = more fake
feature_diff = log_probs[1] - log_probs[0]
sorted_features = sorted(zip(feature_diff, feature_names))

# Most real
print("\nMost indicative of REAL news:")
print([f for _, f in sorted_features[-20:]])

# Get most indicative features for REAL news
most_real = sorted(zip(feature_diff, feature_names), reverse=True)[:20]
print("Most indicative of REAL news:\n")
for score, word in most_real:
    print(f"{word}: {score:.4f}")

# Most fake
print("Most indicative of FAKE news:")
print([f for _, f in sorted_features[:20]])

# Get most indicative features for REAL news
most_real = sorted(zip(feature_diff, feature_names))[:20]
print("Most indicative of FAKE news:\n")
for score, word in most_real:
    print(f"{word}: {score:.4f}")

"""### **Creation of WordCloud**"""

!pip install wordcloud

from wordcloud import WordCloud
import matplotlib.pyplot as plt

text = " ".join(feature_names)  # or use only top fake/real features
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)

plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis("off")
plt.title("Word Cloud of Features")
plt.show()
plt.savefig("Word Cloud of Features using TF-IDF")

"""# **HashingVectorizer**

- **HashingVectorizer** transforms text into feature vectors using a hashing trick. **It does not check for collisions** and **produces both positive and negative values.**

- MultinomialNB assumes that input features represent counts (non-negative), so **it cannot accept negative values.**
"""

from sklearn.feature_extraction.text import HashingVectorizer
hs_vectorizer = HashingVectorizer(n_features=5000, ngram_range=(1,3), non_negative=True)
X = hs_vectorizer.fit_transform(corpus).toarray()

hs_vectorizer = HashingVectorizer(n_features=5000, ngram_range=(1,3))
X = hs_vectorizer.fit_transform(corpus).toarray()

X.shape

X

# Split the dataset into Train and Test
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=42)

from sklearn.naive_bayes import MultinomialNB
classifier=MultinomialNB()
classifier.fit(X_train, y_train)
pred = classifier.predict(X_test)
score = metrics.accuracy_score(y_test, pred)
print("accuracy:   %0.3f" % score)
cm = metrics.confusion_matrix(y_test, pred)
plot_confusion_matrix(cm, classes=['FAKE', 'REAL'])