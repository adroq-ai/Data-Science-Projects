# -*- coding: utf-8 -*-
"""Fake News Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qTWtSlNlIelX7X8xrs-7H_GOO03ZQRxH

#**Fake News**

Build a system to identify unreliable news articles

## **Dataset Description**

**train.csv:** A full training dataset with the following attributes:

* **id:** unique id for a news article
* **title:** the title of a news article
* **author:** author of the news article
* **text:** the text of the article; could be incomplete
* **label:** a label that marks the article as potentially unreliable



        1: unreliable

        0: reliable

# **Installing require Tools**
"""

!pip install gradio

"""# **Import the Libraries**"""

import numpy as np
import pandas as pd
import re  # For regular expressions to clean the text
from nltk.corpus import stopwords   # For filtering out common stop words
from nltk.stem.porter import PorterStemmer   # For stemming words
from sklearn.feature_extraction.text import TfidfVectorizer  # To convert text data into numerical data
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import gradio as gr

import nltk
nltk.download('stopwords')

# printing the stopwords in English
print(stopwords.words('english'))

"""# **Data Collection and Data Preprocessing**"""

# Loading the dataset into a pandas DataFrame
news_data = pd.read_csv('train.csv', on_bad_lines='skip', engine='python')  # Use this to identify issues

# Checking the shape of the dataset
news_data.shape    # Outputs the number of rows and columns in the dataset.

# Checking the numer of missing values in the dataset
print(news_data.isnull().sum())

# Displays the first 5 rows of the dataset.
news_data.head()

# Replace missing or NaN values with an empty string
news_data.fillna('', inplace=True)  # Fill missing values with an empty string

# Checking the shape of the dataset
news_data.shape    # Outputs the number of rows and columns in the dataset.

# Merging the author name and news title
news_data['content'] = news_data['author']+' '+news_data['title']

print(news_data['content'])

news_data.head()

# Splitting features (X) and target (y)
X = news_data.drop(columns='label', axis=1)
y = news_data['label']

print(X)
print(y)

"""#**Stemming**

Stemming is the process of reducing a word to its **Root-word**


Example

Classifier, Classification, Classified  ----> Class

"running" â†’ "run"
"""

# Initialize a Porter Stemmer instance
port_stem = PorterStemmer()

# Define a function to preprocess and stem text
def stemming(content):
    """
    Function to clean, lower case, split, remove stop words, and stem the input text content.

    Args:
    content (str): A string containing the text to process.

    Returns:
    str: The processed and stemmed string.
    """
    # Remove all non-alphabetic characters from the text and replace them with spaces
    stemmed_content = re.sub('[^a-zA-Z]', ' ', content)

    # Convert the cleaned text to lowercase
    stemmed_content = stemmed_content.lower()

    # Split the text into individual list of words (tokens)
    stemmed_content = stemmed_content.split()

    # Stem each word in the text that is not a stopword
    # 'stopwords.words('english')' provides a list of common English stop words
    stemmed_content = [
        port_stem.stem(word) for word in stemmed_content
        if word not in stopwords.words('english')
    ]

    # Join the processed words back into a single string
    stemmed_content = ' '.join(stemmed_content)

    # Return the final processed and stemmed text
    return stemmed_content

print(news_data['content'])

# Apply the `stemming` function to each row in the 'content' column
# This cleans, lowers, removes stopwords, and stems the text in the column
news_data['content'] = news_data['content'].apply(stemming)

"""# **OR**"""

# Splitting features (X) and target (y)
X = news_data['content'].values
y = news_data['label'].values

print(X)

print(y)

y.shape

# -- Converting the textual data to numerical data
# The TfidfVectorizer converts raw text into a numerical representation based on
# Term Frequency-Inverse Document Frequency (TF-IDF) values.
vectorizer = TfidfVectorizer()

# -- Fit the vectorizer to the raw text data
# The fit method learns the vocabulary and calculates document frequencies of terms
# from the input text data 'X'. Here, 'X' must contain raw text data.
vectorizer.fit(X)

# -- Transform the raw text data into numerical format
# After fitting the vectorizer, the transform method converts the text into
# a sparse matrix where each row corresponds to a document, and each column
# corresponds to a term's TF-IDF value in that document.
X = vectorizer.transform(X)

print(X)

"""# **Splitting the Dataset into Training and Test Sets**"""

# Splitting the dataset into Training set and Test Set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=1)

# checking the number of Test and Train dataset
print(X.shape, X_train.shape, X_test.shape)

"""# **Model Training --> Logistic Regression**"""

# Initializing the Logistic Regression model
model = LogisticRegression()

# Training the Logistic Regression model with train data
model.fit(X_train, y_train)

"""# **Model Evaluation**"""

# Calculate accuracy on the training data
X_train_pred = model.predict(X_train)
train_data_accuracy = accuracy_score(X_train_pred, y_train)
print('Accuracy on training data : ', train_data_accuracy)

# Generate and display the confusion matrix on the training data
# The confusion matrix shows the counts of True Positives, True Negatives, False Positives, and False Negatives
conf_matrix = confusion_matrix(y_train, X_train_pred)
print("\nConfusion Matrix:")
print(conf_matrix)

# Step 4: Generate and display the classification report
# The classification report includes precision, recall, F1-score, and support for each class
class_report = classification_report(y_train, X_train_pred, target_names=["Reliable (0)", "Unreliable (1)"])
print("\nClassification Report:")
print(class_report)

# accuracy on the test data
X_test_pred = model.predict(X_test)
test_data_accuracy = accuracy_score(X_test_pred, y_test)
print('Accuracy on test data : ', test_data_accuracy)

# Generate and display the confusion matrix on the test data
# The confusion matrix shows the counts of True Positives, True Negatives, False Positives, and False Negatives
conf_matrix = confusion_matrix(y_test, X_test_pred)
print("\nConfusion Matrix:")
print(conf_matrix)

# Step 4: Generate and display the classification report
# The classification report includes precision, recall, F1-score, and support for each class
class_report = classification_report(y_test, X_test_pred, target_names=["Reliable (0)", "Unreliable (1)"])
print("\nClassification Report:")
print(class_report)

"""# **Making a Predictive System**"""

# Define the predictive system function
def predict_news_reliability(input_text, model, vectorizer):
    """
    Predict whether a given news article is reliable or unreliable.

    Parameters:
        input_text (str): The text of the news article to predict.
        model: The trained machine learning model.
        vectorizer: The fitted TfidfVectorizer instance.

    Returns:
        str: "Reliable" or "Unreliable" based on the model's prediction.
    """
    # Preprocess the input text
    preprocessed_text = stemming(input_text)  # Apply the same stemming function used in training

    # Convert text to numerical data using the vectorizer
    vectorized_input = vectorizer.transform([preprocessed_text])  # Convert to numerical format

    # Make a prediction using the trained model
    prediction = model.predict(vectorized_input)

    #  Map the prediction to the corresponding label
    if prediction[0] == 0:
        return "The news is Real"
    else:
        return "The news is Fake"

# Assuming `model` is the trained classifier and `vectorizer` is the fitted TfidfVectorizer
input_text = "Breaking news: The economy is seeing unprecedented growth due to new policies."
prediction_result = predict_news_reliability(input_text, model, vectorizer)

print(f"The news article is predicted to be: {prediction_result}")

"""# **OR**"""

X_new = X_test[1]

prediction = model.predict(X_new)
print(prediction)

if (prediction[0]==0):
  print('The news is Real')
else:
  print('The news is Fake')

print(y_test[1])

X_new = X_test[2]

prediction = model.predict(X_new)
print(prediction)

if (prediction[0]==0):
  print('The news is Real')
else:
  print('The news is Fake')

print(y_test[2])

X_new = X_test[3]

prediction = model.predict(X_new)
print(prediction)

if (prediction[0]==0):
  print('The news is Real')
else:
  print('The news is Fake')

print(y_test[3])

# Define the predictive system function
def predict_news_reliability(input_text):
    """
    Predict whether a given news article is reliable or unreliable.

    Parameters:
        input_text (str): The text of the news article to predict.

    Returns:
        str: "The news is Real" or "The news is Fake" based on the model's prediction.
    """
    try:
        # Preprocess the input text
        preprocessed_text = stemming(input_text)  # Apply stemming function

        # Convert text to numerical data using the vectorizer
        vectorized_input = vectorizer.transform([preprocessed_text])  # Convert to numerical format

        # Make a prediction using the trained model
        prediction = model.predict(vectorized_input)

        # Map the prediction to the corresponding label
        if prediction[0] == 0:
            return "The news is Real"
        else:
            return "The news is Fake"
    except Exception as e:
        return f"Error: {str(e)}"

# Define the Gradio interface
interface = gr.Interface(
    fn=predict_news_reliability,
    inputs="text",
    outputs="text",
    title="News Reliability Predictive System",
    description=(
        "This system predicts whether a news article is Real or Fake. "
        "Please enter the text of the article to get the prediction."
    ),
    examples=[
        ["Breaking news! Scientists discover water on Mars."],
        ["Click here to win a free iPhone! This is not a scam."],
    ],
)

# Launch the Gradio interface
interface.launch()