# -*- coding: utf-8 -*-
"""Handwritten Digit images Generator - DCGAN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ox6kh_9gyggPHK2viMz3hOC6xR2IPHNJ

###**Installing the necessary libraries**
"""

!pip install tensorflow imageio tensorflow-docs

import glob
import imageio
import matplotlib.pyplot as plt
import numpy as np
import os
import PIL
import tensorflow as tf
from tensorflow.keras import layers
import time
from IPython import display

"""####**Loading the MNIST Handwritten Digit Dataset**"""

(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()

# shape of the Train Images
train_images.shape

train_images[0]

train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')
train_images = (train_images - 127.5) / 127.5   # Normalize the images to [-1, 1]

# shape of the Train Images
train_images.shape

Buffer_size = 60000 # To shuffle the datasets
Batch_size = 256

# Batch and shuffle the data
train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(Buffer_size).batch(Batch_size)

print(train_dataset)

noise = tf.random.normal([1, 100])

print(noise)

print(len(noise))

print(len(noise[0]))

"""###**Model Creation**

- **Generator:** Learns to create fake images from random noise.

- **Discriminator:** Learns to distinguish real images from fake ones.

- **Training Goal:** Generator tries to fool the discriminator; the discriminator tries not to be fooled.

**Generator**
"""

def make_generator_model():
    model = tf.keras.Sequential()

    # 1. Dense layer: Fully connected layer to project the input noise into a larger feature space
    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))

    # 2. Batch normalization: Helps stabilize and speed up training
    model.add(layers.BatchNormalization())

    # 3. LeakyReLU activation: Allows a small gradient when the unit is not active
    model.add(layers.LeakyReLU())

    # 4. Reshape: Converts the flat feature vector into a 3D tensor (7x7x256)
    model.add(layers.Reshape((7, 7, 256)))
    assert model.output_shape == (None, 7, 7, 256)

    # 5. First transposed convolution: Upsample to 7x7x128
    model.add(layers.Conv2DTranspose(
    128,          # Number of output filters (feature maps) — becomes the depth of the output
    (5, 5),       # Kernel size — the filter will be 5x5 in height and width
    strides=(1, 1),# Stride of 1 — controls how much the filter moves per step (no upscaling here)
    padding='same', # Output size will be the same as input size (7x7 in this case)
    use_bias=False  # Do not use bias in this layer (common when followed by BatchNorm)
        )
    )
    assert model.output_shape == (None, 7, 7, 128)  # Ensure expected output shape is achieved
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    # 6. Second transposed convolution: Upsample to 14x14x64
    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))
    assert model.output_shape == (None, 14, 14, 64)
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    # 7. Final transposed convolution: Upsample to 28x28x1 (grayscale image)
    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))
    assert model.output_shape == (None, 28, 28, 1)

    return model

generator = make_generator_model()

# Generate a random noise vector of size 100
noise = tf.random.normal([1, 100])

# Generate an image from the noise (in inference mode)
generated_image = generator(noise, training=False)

# Plot the generated image
plt.imshow(generated_image[0, :, :, 0], cmap='gray')

"""**Discriminator**"""

def make_discriminator_model():
    model = tf.keras.Sequential()

    # 1. Conv layer: Downsample input (28x28x1) to (14x14x64)
    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',
                            input_shape=[28, 28, 1]))
    model.add(layers.LeakyReLU())
    model.add(layers.Dropout(0.3))  # Prevent overfitting

    # 2. Conv layer: Further downsample to (7x7x128)
    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))
    model.add(layers.LeakyReLU())
    model.add(layers.Dropout(0.3))

    # 3. Flatten: Convert 3D feature maps to 1D
    model.add(layers.Flatten())

    # 4. Dense output: One neuron for binary classification (real or fake)
    model.add(layers.Dense(1))

    return model

# using the untrained discriminator to predict whether an image is "Real or "Fake"
discriminator = make_discriminator_model()
decision = discriminator(generated_image)
print (decision)

"""**Loss and Optimizer**"""

# This method returns a helper function to compute cross entropy loss
cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)

"""**Discriminator Loss**

This methods quantifies how well the discriminator is able to distinguish real images from fakes. It compares the discriminator's predictions on real images to an array of 1s, and the disciminator's prediction on fake(generated) images to an array of 0s
"""

tf.ones_like((1,1,1,1,0,1,0,1,1))

tf.zeros_like((1,1,1,1,0,1,0,1,1))

def discriminator_loss(real_output, fake_output):
    real_loss = cross_entropy(tf.ones_like(real_output), real_output)
    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)
    total_loss = real_loss + fake_loss
    return total_loss

"""**Generator Loss**

The generator's loss quantifies how well it was able to trick discriminator. Intuitively, if the generator is performing well, the disciminator will classify the fake images as real(or 1). Here, compare the dicriminators decision in the generated images to an array of 1s
"""

def generator_loss(fake_output):
    return cross_entropy(tf.ones_like(fake_output), fake_output)

"""The discriminator and the generator optimizers are different since we will train two networks separately"""

generator_optimizer = tf.keras.optimizers.Adam(1e-4)
discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)

"""**Saving the checkpoints**"""

checkpoint_dir = './training_checkpoints'
checkpoint_prefix = os.path.join(checkpoint_dir, "ckpt")
checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,
                                 discriminator_optimizer=discriminator_optimizer,
                                 generator=generator,
                                 discriminator=discriminator)

"""**Defining the training Loop**"""

Epochs = 100
noise_dim = 100
num_examples_to_generate = 16

# You will reuse this seed overtime (so it's easier)
# to visualize progress in the animated GIF)
seed = tf.random.normal([num_examples_to_generate, noise_dim])

"""The training loop begins with generator receives a random seeds as input. That seeds is used to produce an image. The discriminator is then used to classify real images (drawn from the training set) and fake images(produced by the generator). The loss is calculated for each of these models, and the gradients are used to update the generator and discriminator."""

# Notice the use of "tf.function",
# this anotation causes the function to be "compiled", (Tensorflow Computation graph)

@tf.function   # decorated function (faster than regular Python)
def train_step(images):
    noise = tf.random.normal([Batch_size, noise_dim])

    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
      generated_images = generator(noise, training=True)

      real_output = discriminator(images, training=True)
      fake_output = discriminator(generated_images, training=True)

      gen_loss = generator_loss(fake_output)
      disc_loss = discriminator_loss(real_output, fake_output)

    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)
    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)

    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))
    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))

def train(dataset, epochs):
  for epoch in range(epochs):
    start = time.time()

    for image_batch in dataset:
      train_step(image_batch)

    # Produce images for the GIF as you go
    display.clear_output(wait=True)
    generate_and_save_images(generator,
                             epoch + 1,
                             seed)

    # Save the model every 15 epochs
    if (epoch + 1) % 15 == 0:
      checkpoint.save(file_prefix = checkpoint_prefix)

    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))

  # Generate after the final epoch
  display.clear_output(wait=True)
  generate_and_save_images(generator,
                           epochs,
                           seed)

"""**Generate and Save images**"""

def generate_and_save_images(model, epoch, test_input):
  # Notice `training` is set to False.
  # This is so all layers run in inference mode (batchnorm).
  predictions = model(test_input, training=False)

  fig = plt.figure(figsize=(4, 4))

  for i in range(predictions.shape[0]):
      plt.subplot(4, 4, i+1)
      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')
      plt.axis('off')

  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))
  plt.show()

"""**Training the model**

Call the train() method defined above to train the generator and discriminator simultaneously. Note, training GANs can be tricky. It's important that the generator and discriminator do not overpower each other(e.g., that they train at a similar rate).

At the begining of the training, the generated images look like a random noise. At training progresses, the generated digits will look incrasingly real. After about 50 epoch, they resemble MNIST digits.
"""

train(train_dataset, Epochs)

checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))

# Display a single image using the epoch number
def display_image(epoch_no):
  return PIL.Image.open("image_at_epoch_{:04d}.png".format(epoch_no))

display_image(Epochs)

"""**Use imageio to create an animated gif using the images saved during training**"""

# Define the output filename for the animation
anim_file = "dcgan.gif"

# Create a writer object to assemble the GIF
with imageio.get_writer(anim_file, mode="I") as writer:

    # Get all generated image filenames (e.g., image_at_epoch_0001.png)
    filenames = glob.glob("image*.png")

    # Sort the filenames to ensure correct frame order
    filenames = sorted(filenames)

    # Add each image to the GIF
    for filename in filenames:
        image = imageio.imread(filename)  # Read the image from file
        writer.append_data(image)         # Add image to GIF

    # Add the final image one more time for a pause at the end
    image = imageio.imread(filename)
    writer.append_data(image)

# Import embed module from tensorflow_docs to help visualize media
import tensorflow_docs.vis.embed as embed

# Embed the previously saved GIF animation inside the notebook
embed.embed_file(anim_file)

"""#####**Save the model to Google drive or local**"""

generator.save('trained_mnist_DCGAN_model.h5')