# -*- coding: utf-8 -*-
"""MNIST Digit Handwritten Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NnRlYqxDWCs0ydEI6YZyh7EPCBi5QcEJ

#**MNIST Handwritten Digit Classification using Deep Learning (Neural Network)**

#**Install the necessary Libraries**
"""

pip install gradio

"""#**Import the Libraries**"""

# Importing the Dependencies
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import cv2
from google.colab.patches import cv2_imshow
from PIL import Image
import tensorflow as tf
tf.random.set_seed(42)
from tensorflow import keras
import tensorflow_datasets as mnist
from tensorflow.keras.models import load_model
from tensorflow.math import confusion_matrix
import gradio as gr

"""#**Data Collection and Preprocessing**



**Loading the MNIST Data from keras datasets**
"""

(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()

type(X_train)

# Shape of the numpy arrays
print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)

"""Training Data ---> 60,000 Images

Test Data    ---> 10,000 Images

Image Dimension  ---> 28 * 28

Grayscale Image ---> 1 channel(Black and White)
"""

# Print the 20th image
print(X_train[20])

# print the 20th label
print(y_train[20])

print(X_train[20].shape)

# Display the Image
plt.imshow(X_train[20])
plt.show()

# Print the Corresponding label
print(y_train[20])

# Display the Image
plt.imshow(X_train[50])
plt.show()

# Print the Corresponding label
print(y_train[50])

# Display the Image
plt.imshow(X_train[10])
plt.show()

# Print the Corresponding label
print(y_train[10])

# Display the Image
plt.imshow(X_train[25])
plt.show()

# Print the Corresponding label
print(y_train[25])

"""**Image Labels**"""

print(y_train.shape, y_test.shape)

# Unique values in Y_train
print("\nUnique values in Y_train:")
print(np.unique(y_train))

# Unique values in Y_test
print("\nUnique values in Y_test:")
print(np.unique(y_test))

"""**We can use these labels as such or perform One Hot Encoding**

**There is no need for dimensioning because all images have common dimension**
"""

# Normalization (Scaling the values to be in range of 0 - 1)
X_train_norm = X_train / 255.0
X_test_norm = X_test / 255.0

# Print the 20th image
print(X_train_norm[20])

"""#**Building the Neural Network**"""

# Setting the layers of the Neural Network
model_1 = keras.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)),
    keras.layers.Dense(128, activation='relu'),
    keras.layers.Dense(10, activation='softmax')
])

# Compling the Neural Network
model_1.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Training the Neural Network
model_1.fit(X_train_norm, y_train, epochs=15)

"""**Training data accuracy : 99.8%**

**Accuracy on Test Data**
"""

# Accuracy on Test Data
loss, accuracy = model_1.evaluate(X_test_norm, y_test)
print("Test Loss:", loss)
print("Test Accuracy:", accuracy)

"""**Test data accuracy : 97.8%**"""

# First data point in X_test
plt.imshow(X_test[0])
plt.show()

print(y_test[0])

y_pred_1 = model_1.predict(X_test_norm)

print(y_pred_1.shape)

print(y_pred_1[0])

print(y_pred_1)

"""**Model.predict() gives the prediction probability of each classes for that point**"""

# Converting the prediction probabilities to class label
y_pred_labels_for_first_image = np.argmax(y_pred_1[0])
print(y_pred_labels_for_first_image)

# Converting the prediction probabilities to class label for all class label
y_pred_labels = [np.argmax(i) for i in y_pred_1]
print(y_pred_labels)

"""**y_test ---> True Labels**

**y_pred_labels ---> Predicted Labels**
"""

conf_mat = confusion_matrix(y_test, y_pred_labels)
print(conf_mat)

# Create the heatmap with enhancements
plt.figure(figsize=(15, 10))
sns.heatmap(
    conf_mat,
    annot=True,
    fmt="d",  # integers
    cmap="coolwarm",
    cbar_kws={"shrink": 0.8},
    linewidths=0.5,
    square=True,
    annot_kws={"size": 8, "weight": "bold"},
)
plt.title("Enhanced Correlation Heatmap", fontsize=14, fontweight="bold", pad=15)
plt.xticks(fontsize=10, weight="bold")
plt.yticks(fontsize=10, weight="bold")
plt.tight_layout()
plt.ylabel("True Labels", fontsize=12, fontweight="bold")
plt.xlabel("Predicted Labels", fontsize=12, fontweight="bold")
plt.show()

"""#**Building a Predictive System**"""

input_img_path = "MNIST_digit.png"

input_img = cv2.imread(input_img_path)

type(input_img)

print(input_img.shape)

cv2_imshow(input_img)

# Converting to Grayscale image
input_img_gray = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)

print(input_img_gray.shape)

# Resizing the image
input_img_gray_resize = cv2.resize(input_img_gray, (28, 28))

print(input_img_gray_resize.shape)

cv2_imshow(input_img_gray_resize)

# Normalization (Scaling the values to be in range of 0 - 1)
input_img_gray_resize_norm = input_img_gray_resize / 255.0

type(input_img_gray_resize_norm)

# Reshaping the image
input_img_gray_resize_norm_reshaped = np.reshape(input_img_gray_resize_norm, [1, 28, 28])

type(input_img_gray_resize_norm_reshaped)

input_img_gray_resize_norm_reshaped.shape

input_pred = model_1.predict(input_img_gray_resize_norm_reshaped)
print(input_pred)

input_pred_label = np.argmax(input_pred)
print(input_pred_label)

"""#**Predictive System**"""

# Enter the path of Image
input_img_path = input("Enter the image path: ")

# Read the image entered
input_img = cv2.imread(input_img_path)

# Display the Image
cv2_imshow(input_img)

# Converting to Grayscale image
input_img_gray = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)

# Resizing the image
input_img_gray_resize = cv2.resize(input_img_gray, (28, 28))

# Normalization (Scaling the values to be in range of 0 - 1)
input_img_gray_resize_norm = input_img_gray_resize / 255.0

# Reshaping the image
input_img_gray_resize_norm_reshaped = np.reshape(input_img_gray_resize_norm, [1, 28, 28])

# Predicting the Image
input_pred = model_1.predict(input_img_gray_resize_norm_reshaped)

# Choosing the maximum value
input_pred_label = np.argmax(input_pred)
print("The Handwritten Image is Recognised as: ", input_pred_label)

# Enter the path of Image
input_img_path = input("Enter the image path: ")

# Read the image entered
input_img = cv2.imread(input_img_path)

# Display the Image
cv2_imshow(input_img)

# Converting to Grayscale image
input_img_gray = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)

# Resizing the image
input_img_gray_resize = cv2.resize(input_img_gray, (28, 28))

# Normalization (Scaling the values to be in range of 0 - 1)
input_img_gray_resize_norm = input_img_gray_resize / 255.0

# Reshaping the image
input_img_gray_resize_norm_reshaped = np.reshape(input_img_gray_resize_norm, [1, 28, 28])

# Predicting the Image
input_pred = model_1.predict(input_img_gray_resize_norm_reshaped)

# Choosing the maximum value
input_pred_label = np.argmax(input_pred)
print("The Handwritten Image is Recognised as: ", input_pred_label)

# Enter the path of Image
input_img_path = input("Enter the image path: ")

# Read the image entered
input_img = cv2.imread(input_img_path)

# Display the Image
cv2_imshow(input_img)

# Converting to Grayscale image
input_img_gray = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)

# Resizing the image
input_img_gray_resize = cv2.resize(input_img_gray, (28, 28))

# Normalization (Scaling the values to be in range of 0 - 1)
input_img_gray_resize_norm = input_img_gray_resize / 255.0

# Reshaping the image
input_img_gray_resize_norm_reshaped = np.reshape(input_img_gray_resize_norm, [1, 28, 28])

# Predicting the Image
input_pred = model_1.predict(input_img_gray_resize_norm_reshaped)

# Choosing the maximum value
input_pred_label = np.argmax(input_pred)
print("The Handwritten Image is Recognised as: ", input_pred_label)

"""#**Building another model**"""

# Setting the layers of the Neural Network
model_2 = keras.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)),
    keras.layers.Dense(50, activation='relu'),
    keras.layers.Dense(75, activation='relu'),
    keras.layers.Dense(10, activation='sigmoid')
])

# Compling the Neural Network
model_2.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Training the Neural Network
model_2.fit(X_train_norm, y_train, epochs=25)

"""**Training data accuracy : 99.5%**

**Accuracy on Test Data**
"""

# Accuracy on Test Data
loss, accuracy = model_2.evaluate(X_test_norm, y_test)
print("Test Loss:", loss)
print("Test Accuracy:", accuracy)

"""**Test data accuracy : 97.4%**"""

model = model_2.save("your_trained_model.h5")

# Enter the path of Image
input_img_path = input("Enter the image path: ")

# Read the image entered
input_img = cv2.imread(input_img_path)

# Display the Image
cv2_imshow(input_img)

# Converting to Grayscale image
input_img_gray = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)

# Resizing the image
input_img_gray_resize = cv2.resize(input_img_gray, (28, 28))

# Normalization (Scaling the values to be in range of 0 - 1)
input_img_gray_resize_norm = input_img_gray_resize / 255.0

# Reshaping the image
input_img_gray_resize_norm_reshaped = np.reshape(input_img_gray_resize_norm, [1, 28, 28])

# Predicting the Image
input_pred = model_2.predict(input_img_gray_resize_norm_reshaped)

# Choosing the maximum value
input_pred_label = np.argmax(input_pred)
print("The Handwritten Image is Recognised as: ", input_pred_label)

# Enter the path of Image
input_img_path = input("Enter the image path: ")

# Read the image entered
input_img = cv2.imread(input_img_path)

# Display the Image
cv2_imshow(input_img)

# Converting to Grayscale image
input_img_gray = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)

# Resizing the image
input_img_gray_resize = cv2.resize(input_img_gray, (28, 28))

# Normalization (Scaling the values to be in range of 0 - 1)
input_img_gray_resize_norm = input_img_gray_resize / 255.0

# Reshaping the image
input_img_gray_resize_norm_reshaped = np.reshape(input_img_gray_resize_norm, [1, 28, 28])

# Predicting the Image
input_pred = model_2.predict(input_img_gray_resize_norm_reshaped)

# Choosing the maximum value
input_pred_label = np.argmax(input_pred)
print("The Handwritten Image is Recognised as: ", input_pred_label)

# Enter the path of Image
input_img_path = input("Enter the image path: ")

# Read the image entered
input_img = cv2.imread(input_img_path)

# Display the Image
cv2_imshow(input_img)  # For Colab users; use cv2.imshow() for local execution

# Convert the image to grayscale
input_img_gray = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)

# Resize the image to 28x28 pixels (same as the MNIST dataset)
input_img_gray_resize = cv2.resize(input_img_gray, (28, 28))

# Normalize pixel values (scaling to range 0 - 1)
input_img_gray_resize_norm = input_img_gray_resize / 255.0

# Reshape the image to match the model's expected input shape
input_img_gray_resize_norm_reshaped = np.reshape(input_img_gray_resize_norm, [1, 28, 28])

# Predict the digit in the image
input_pred = model_2.predict(input_img_gray_resize_norm_reshaped)

# Get the class label with the highest probability
input_pred_label = np.argmax(input_pred)
print("The Handwritten Image is Recognised as: ", input_pred_label)

def predict_MNIST_Image_Handwritten(input_data):
    input_img = cv2.imread(input_data)

    # Display the Image
    cv2_imshow(input_img)

    # Converting to Grayscale image
    input_img_gray = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)

    # Resizing the image
    input_img_gray_resize = cv2.resize(input_img_gray, (28, 28))

    # Normalization (Scaling the values to be in range of 0 - 1)
    input_img_gray_resize_norm = input_img_gray_resize / 255.0

    # Reshaping the image
    input_img_gray_resize_norm_reshaped = np.reshape(input_img_gray_resize_norm, [1, 28, 28])

    # Predicting the Image
    input_pred = model_2.predict(input_img_gray_resize_norm_reshaped)


# Enter the path of Image
input_img_path = input("Enter the image path: ")

# Display the Image
cv2_imshow(input_img)


# Choosing the maximum value
input_pred_label = np.argmax(input_pred)
print("The Handwritten Image is Recognised as: ", input_pred_label)

# Load the trained model
model = load_model("your_trained_model.h5")  # Ensure your model is saved and available

def predict_MNIST_Image_Handwritten(image_path):
    """
    Predicts a handwritten digit from an input image using a trained model.

    Parameters:
        image_path (str): The file path of the image to be processed.

    Returns:
        int: The predicted digit (0-9).
    """

    # Read the image
    input_img = cv2.imread(image_path)

    # Validate image loading
    if input_img is None:
        print("Error: Could not read the image. Check the file path.")
        return None

    # Display the image
    cv2_imshow(input_img)

    # Convert to grayscale
    input_img_gray = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)

    # Resize to 28x28 (same as MNIST dataset)
    input_img_gray_resize = cv2.resize(input_img_gray, (28, 28))

    # Normalize pixel values (scale between 0 and 1)
    input_img_gray_resize_norm = input_img_gray_resize / 255.0

    # Reshape to match model input shape (batch_size, height, width, channels)
    input_img_gray_resize_norm_reshaped = np.reshape(input_img_gray_resize_norm, (1, 28, 28, 1))

    # Make a prediction
    input_pred = model.predict(input_img_gray_resize_norm_reshaped)

    # Get the predicted digit (the index of the max value)
    input_pred_label = np.argmax(input_pred)

    print("The Handwritten Image is Recognised as:", input_pred_label)

    return input_pred_label

# Request user input for image path
input_img_path = input("Enter the image path: ")

# Predict and display the result
predict_MNIST_Image_Handwritten(input_img_path)

# Load the trained model
model_2 = load_model("your_trained_model.h5")  # Load the saved model, ensure you have a trained model

def predict_digit(img):
    """Preprocess image and predict the handwritten digit."""
    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert to grayscale
    img_resized = cv2.resize(img_gray, (28, 28))      # Resize to 28x28 pixels
    img_normalized = img_resized / 255.0              # Normalize pixel values
    img_reshaped = img_normalized.reshape(1, 28, 28, 1)  # Reshape for the model

    prediction = model_2.predict(img_reshaped)  # Predict
    predicted_label = np.argmax(prediction)  # Get the class label

    return f"The handwritten digit is: {predicted_label}"

# Create Gradio interface
interface = gr.Interface(
    fn=predict_digit,
    inputs=gr.Image(type="numpy"),
    outputs="text",
    title="Handwritten Digit Recognition",
    description="Upload a handwritten digit image, and the model will recognize it."
)

# Launch the interface
interface.launch()